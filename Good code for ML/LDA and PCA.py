# -*- coding: utf-8 -*-
"""Class 8: LDA and PCA - master.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cghVDqwXMJs4E21iZRii-CiDtfomQOqm

# Import packages
"""

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

"""# Import data"""

# Import data from URL and add column names
wine_df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header = None)
wine_df.columns = ['Label', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', 
                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 
                   'OD280/OD315 of diluted wines', 'Proline']

"""# Initial data exploration"""

# Top n rows
wine_df.head()

# Get shape of dataframe
wine_df.shape

# Labels represent each of the three different types of wine
wine_df['Label'].value_counts()

sns.distplot(wine_df['Alcohol'])

"""# Data transformations"""

# Separate labels, so we don't scale the categorical values
wine_features = wine_df.iloc[:, 1:]
wine_labels = wine_df.iloc[:,0]

# Normalize data so each variable has appropriate influence
sc = StandardScaler()
wine_features_std = sc.fit_transform(wine_features)

# Convert numpy array to pandas dataframe and add columns back
wine_features_std = pd.DataFrame(wine_features_std)
wine_features_std.columns = wine_features.columns
wine_features_std.head()

"""# LDA"""

# Define and fit standardized data
lda = LDA()
ld = lda.fit_transform(wine_features_std, wine_labels)
lda_df = pd.DataFrame(data = ld, 
        columns = ['LDA1', 'LDA2'])
lda_df['Cluster'] = wine_labels

# Print results of classification of training data
print('Accuracy of LDA classifier on training set: {:.2f}'
     .format(lda.score(wine_features_std, wine_labels)))
# print('Accuracy of LDA classifier on test set: {:.2f}'
#      .format(lda.score(X_test, y_test)))

# Print top n observations of LDA df
lda_df.head()

lda.predict(wine_features_std)

# Scatter plot of the first and second linear discriminant (LDA1, LDA2) clustered by wine label
sns.lmplot(x="LDA1", y="LDA2",
  data=lda_df, 
  fit_reg=False, 
  hue='Cluster', # color by cluster
  legend=True,
  scatter_kws={"s": 80}) # specify the point size

# Scatter plot of the first linear discriminant (LDA1) by wine label
sns.lmplot(x="LDA1", y="Cluster",
  data=lda_df, 
  fit_reg=False, 
  hue='Cluster', # color by cluster
  legend=True,
  scatter_kws={"s": 80}) # specify the point size

"""# PCA"""

wine_features.head()

# Define number of principal components
# Source: https://cmdlinetips.com/2018/03/pca-example-in-python-with-scikit-learn/

pca = PCA(n_components=3)

# Fit to features
pc = pca.fit_transform(wine_features)

# Dataframe of principal components and wine labels
pc_df = pd.DataFrame(data = pc, 
        columns = ['PC1', 'PC2','PC3'])
pc_df['Cluster'] = wine_labels
pc_df.head()

# Scree plot
# What went wrong?
pca_df = pd.DataFrame({'var':pca.explained_variance_ratio_,
             'PC':['PC1','PC2','PC3']})
sns.barplot(x='PC',y="var", 
           data=pca_df, color="c")

# Scatter plot of the first and second principal components (PC1, PC2) clustered by wine label
sns.lmplot( x="PC1", y="PC2",
  data=pc_df, 
  fit_reg=False, 
  hue='Cluster', # color by cluster
  legend=True,
  scatter_kws={"s": 80}) # specify the point size

# Define number of principal components
pca = PCA(n_components=3)

# Fit to features
pc = pca.fit_transform(wine_features_std)

# Dataframe of principal components and wine labels
pc_df = pd.DataFrame(data = pc, 
        columns = ['PC1', 'PC2','PC3'])
pc_df['Cluster'] = wine_labels
pc_df.head()

# Scree plot
pca_df = pd.DataFrame({'var':pca.explained_variance_ratio_,
             'PC':['PC1','PC2','PC3']})
sns.barplot(x='PC',y="var", 
           data=pca_df, color="c")

# Scatter plot of the first and second principal components (PC1, PC2) clustered by wine label
sns.lmplot( x="PC1", y="PC2",
  data=pc_df, 
  fit_reg=False, 
  hue='Cluster', # color by cluster
  legend=True,
  scatter_kws={"s": 80}) # specify the point size

# Scatter plot of the first and third principal components (PC1, PC3) clustered by wine label
# What does this tell us?
sns.lmplot( x="PC1", y="PC3",
  data=pc_df, 
  fit_reg=False, 
  hue='Cluster', # color by cluster
  legend=True,
  scatter_kws={"s": 80}) # specify the point size

# PCA biplot

# Scatter plot based and assigned color based on 'label - y'
sns.lmplot('PC1', 'PC2', data=pc_df, fit_reg = False, size=10, hue = 'Cluster', scatter_kws={"s": 100})
 
# set the maximum variance of the first two PCs
# this will be the end point of the arrow of each **original features**
xvector = pca.components_[0]
yvector = pca.components_[1]
 
# value of the first two PCs, set the x, y axis boundary
xs = pca.transform(wine_features_std)[:,0]
ys = pca.transform(wine_features_std)[:,1]
 
## visualize projections
 
## Note: scale values for arrows and text are a bit inelegant as of now,
##       so feel free to play around with them
for i in range(len(xvector)):
    # arrows project features (ie columns from csv) as vectors onto PC axes
    # we can adjust length and the size of the arrow
    plt.arrow(0, 0, xvector[i]*max(xs), yvector[i]*max(ys),
              color='r', width=0.005, head_width=0.05)
    plt.text(xvector[i]*max(xs)*1.1, yvector[i]*max(ys)*1.1,
             list(wine_features.columns.values)[i], color='r')
 
plt.title('PCA Plot of first PCs')

# PCA biplot
# Source: https://thehongwudotcom.wordpress.com/2016/02/28/biplot-in-python-optimized-with-color-scatter-plot/

# Scatter plot based and assigned color based on 'label - y'
sns.lmplot('PC1', 'PC3', data=pc_df, fit_reg = False, size=10, hue = 'Cluster', scatter_kws={"s": 100})
 
# set the maximum variance of the first two PCs
# this will be the end point of the arrow of each **original features**
xvector = pca.components_[0]
yvector = pca.components_[2]
 
# value of the first two PCs, set the x, y axis boundary
xs = pca.transform(wine_features_std)[:,0]
ys = pca.transform(wine_features_std)[:,2]
 
## visualize projections
 
## Note: scale values for arrows and text are a bit inelegant as of now,
##       so feel free to play around with them
for i in range(len(xvector)):
    # arrows project features (ie columns from csv) as vectors onto PC axes
    # we can adjust length and the size of the arrow
    plt.arrow(0, 0, xvector[i]*max(xs), yvector[i]*max(ys),
              color='r', width=0.005, head_width=0.05)
    plt.text(xvector[i]*max(xs)*1.1, yvector[i]*max(ys)*1.1,
             list(wine_features.columns.values)[i], color='r')
 
plt.title('PCA Plot of first PCs')