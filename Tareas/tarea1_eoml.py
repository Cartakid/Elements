# -*- coding: utf-8 -*-
"""Tarea1-EoML Juan Jose.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SC8tm5AkgEp_FX0EngOEy2d2cW0qOCtV

Haz una copia de este notebook. Responde a las preguntas conceptuales agregando una célula de texto, y las preguntas de aplicación usando código o texto como te parezca conveniente. Las preguntas son adaptadas del libro ¨Introduction to Statistical Learning¨ de  Gareth James, Daniela Witten, Trevor Hastie y Robert Tibshirani (http://www-bcf.usc.edu/~gareth/ISL/data.html)

# Tarea 1. Elements of Machine Learning. UFM

- - -
# Conceptual

## 1:
Para cada uno de los siguientes, indica si en general esperarías que un método de aprendizaje flexible le iría mejor que a uno inflexible en cada caso. Justifica tus respuestas:



> a. El tamaño muestral $n$ es extremadamente pequeño, y el número de predictores $p$ es pequeño
>>El método inflexible sería mejor porque *n* es pequeño y los predictores *p* también.

> b. El número de predictores $p$ es extremadamente grande, y el número de observaciones $n$ es pequeño
>>El método inflexible es mejor porque el método flexible tuviera mucho ruido y patrones innecesarios.

> c. La relación entre los predictores y la respuesta es altamente no-lineal
>>El método flexible tiene facilidad para la relación no-lineal mientras que el método inflexible tiene muchos problemas.

> d. La varianza de los errores aleatorios, $\mathbb{V}[\epsilon]$, es extremadamente alta
>>Debido a que la varianza es alta, es mejor utilizar el método inflexible

## 2:
El DataFrame generado en el siguiente código contiene train data con seis observaciones: tres predictores $X_1$, $X_2$, y $X_3$ y una variable de respuesta cualitativa $Y$. Imagina que queremos usar esta información para hacer predicciones de Y cuando $X_1=X_2=X_3=0$ usando K-nearest neighbors
"""

from __future__ import print_function

import pandas as pd
pd.__version__

X_1 = pd.Series([0,2,0,0,-1,1])
X_2 = pd.Series([3,0,1,1,0,1])
X_3 = pd.Series([0,0,3,2,1,1])
Y = pd.Series(['Red','Red','Red','Green','Green','Red'])

TrainData = pd.DataFrame({"X_1":X_1, "X_2":X_2, "X_3":X_3, "Y":Y})
TrainData

"""> a. Evalúa la distancia euclidiana entre cada observación y el origen $X_1=X_2=X_3=0$
>>Observacion 0  tiene una distancia de 3
>>>sqrt((0-0)^2+(3-0)^2+(0-0)^2)=3

>>Observacion 1  tiene una distancia de 2
>>>sqrt((2-0)^2+(0-0)^2+(0-0)^2)=2

>>Observacion 2  tiene una distancia de 3.16 
>>>sqrt((0-0)^2+(1-0)^2+(3-0)^2)=3.16

>>Observacion 3  tiene una distancia de 2.24 
>>>sqrt((0-0)^2+(1-0)^2+(2-0)^2)=2.24

>>Observacion 4  tiene una distancia de 1.41 
>>>sqrt((-1-0)^2+(0-0)^2+(1-0)^2)=1.41

>>Observacion 5  tiene una distancia de 1.73 
>>>sqrt((-1-0)^2+(1-0)^2+(1-0)^2)=1.73

> b. ¿Qué predicción harías para K = 1? ¿Por qué?
>>La prediccion sería verde porque la observación 5 tuvo 1.41 y fue verde.

> c. ¿Qué predicción harías para K = 3? ¿Por qué?
>>Es rojo porque con la observación 2, 5 y 6 se analizan las y porque tienen las distancias más pequeñas.

> d. Si la frontera de decisión de Bayes en este problema es altamente no-lineal, ¿esperaríamos entonces que el mejor valor de K sea grande o pequeño? ¿Por qué?
>>el valor sería pequeño debido a alta varianza que causa la frontera de decisión Bayes.

## 3:

**Ejercicio 2.4.2**
>**a). Entender los factores que afectan el salario de CEO**
>>Es un problema de regresión porque el salario es una variable continua y n=500 porque son las firmas y p=3 ingresos, números de empleos e industria.


>**b). Nuevo producto **
>>Es un problema de clasificación porque se quiere saber si será exitoso o no. N=20 por la muestra y p=13 por los criterios (precio, presupuesto de mercadeo, precio competitivo y 10 variables)

>**c). Dólar en la bolsa **
>>Es un problema de regresion porque la variable que se busca es cuantitativa y también es predictivo porque queremos predecir el cambio%. N=52 semanas del año y p=3 las variables recolectadas por cada semana.

## 4:

**Ejercicio 2.4.4 Ejemplos de la vida real**
>**a)clasificación**
>>   Si el ejercicio físico esta siendo correctamente realizado por medio de sensores.
>>   Predecir flores por medio de un dataset que tenga tallos y pedales.
>>Predecir si nace hombre o mujer dependiendo del porcentaje de nacimientos en el mes.

>**b)regresión**
>>  Predecir precios de inmuebles por medio de la zona, accesibilidad e industria de los inmuebles cercanos.
>>Salario por medio de la educación académica, experiencia laboral, edad y años en el campo.
>>Precios de carros por el kilometraje, modelo, marca, línea, motor, accesorios internos y ADAS.

>**c)cluster**
>>Programa de lealtad en un hospital por medio de los accidentes más frecuentes por zona.
>>Nicho de mercado por medio edad de los clientes, ingresos y comportamiento de compra.
>>Entender la genética de las personas por medio de clasificar el ADN en subgrupos para indicar que medicamentos o posibles enfermedades puede tener.

- - -
# Aplicado

## 5:
Use los datos en el archivo College.csv encontrado en el enlace http://www-bcf.usc.edu/~gareth/ISL/data.html. Puede descargar el archivo csv y subirlo a su sesión de Google Colab de la siguiente manera:

```python
from google.colab import files 
upload = files.upload()
```

Le pedirá elegir un archivo, el cual debe de ser el archivo que descargó previamente. Use `panda` para explorarlo como DataFrame y notar que contiene 18 variables para 777 diferentes universidades en Estados Unidos. Las variables son


*   *Private*: Public/private
*   *Apps*: Número de aplicaciones
*   *Accept*: Número de aplicaciones aceptadas
*   *Enroll*: Número de estudiantes inscritos
*   *Top10perc*: Nuevos estudiantes del top 10% de su clase de secundaria
*   *Top25perc*: Nuevos estudiantes del top 25% de su clase de secundaria
*   *F.Undergrad*: Número de undergrads de tiempo completo
*   *P.Undergrad*: Número de undergrads de tiempo parcial
*   *Outstate*: Out-of-state tuititon
*   *Room.Board*: Costos de cuarto
*   *Books*: Costos de libros estimados
*   *Personal*: Costos personales estimados
*   *PhD*: Porcentaje de la facultad con PhD's
*   *Terminal*: Porcentaje de la facultad con título más alto en su disciplina
*   *S.F.Ratio*: Razón entre estudiantes y miembros de la facultad
*   *perc.alumni*: Porcentaje de alumnos que hacen donaciones
*   *Expend*: Gastos de instrucción por estudiante
*   *Grad.Rate*: Razón de alumnos graduados

> a. Explora los datos usando panda y las funciones .describe(), head().

> b. Agrega una nueva serie con el porcentaje de aplicaciones aceptadas calculado a partir de las variables en el archivo

> c. Haz un histograma del porcentaje de aplicaciones aceptadas usando la función .hist('-') donde '-' es la variable que creaste en b

> d. ¿Qué observaciones tienes sobre las 777 universidades luego de explorar los datos?
"""

from google.colab import files 
upload = files.upload()
import pandas as pd
import io
df=pd.read_csv("College.csv", index_col=0)

#Demostrar las columnas y las primeras 5 universidades
df.head()

#Un resumen estadistico de las variables
df.describe()

#Aceptadas en %
df['Accepted'] = df.Accept/df.Apps*100
df.head()

#histrograma
df.hist(column='Accepted')

#observaciones
len(df.index)