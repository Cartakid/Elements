# -*- coding: utf-8 -*-
"""Tarea2-EoML Juan Jose.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XpoyS5vHO1RvNvY_miqNmYKEC6g5riVQ

# Problemas Conceptuales

## Problema 1

Suponga que tenemos datos con cinco predictores: $X_1=\text{GPA}$ (promedio de calificaciones), $X_2=\text{IQ}$, $X_3=\text{Genero}$ (1 para Mujeres y 0 para Hombres), $X_4=\text{Interaccion entre GPA y IQ}$ y $X_5=\text{Interaccion entre GPA y Genero}$.

La respuesta es el salario inicial luego de graduarse después de graduarse (en miles de dólares). Suponga que utilizamos el ajuste de mínimos cuadrados para ajustar al modelo, obteniendo así $\hat\beta_0=50$, $\hat\beta_1=20$, $\hat\beta_2=0.07$, $\hat\beta_3=35$, $\hat\beta_0=4=0.01$ y $\hat\beta_0=5=-10$.

1. ¿Cuál de las siguientes afirmaciones es correcta? ¿Por qué?
    1. Para un valor fijo de IQ y GPA, los hombres ganan más en promedio que las mujeres.
    2. Para un valor fijo de IQy GPA, las mujeres ganan más en promedio que los hombres.
    3. Para un valor fijo de IQ y GPA, los hombres ganan más en promedio que las mujeres, siempre que el GPA sea lo suficientemente alto.
    4. Para un valor fijo de IQ y GPA, las mujeres ganan más en promedio que los hombres, siempre que el GPA sea lo suficientemente alto.

La 3 porque cuando el GPA es alto, es mejor el salario para los hombres.

y=50+20GPA+0.07IQ+35Genero+0.01GPAxIQ-10GPAxGenero.

para hombres: 
> y=50+20GPA+0.07IQ+0.01GPAxIQ

para mujeres:
>y=85+10GPA+0.07IQ+0.01GPAxIQ

Para saber cuando el salario de los hombres es mayor al de las mujeres.
>50+20GPA=85+10GPA
>GPA≥3.5

2. Prediga el salario de una mujer con $\text{IQ}=110$ y $\text{GPA}=4.0$.

y=85+10GPA+0.07IQ+0.01GPAxIQ

y=85*10(4.0)+0.07(110)+0.01(4.0)110

y=137.1

3. Verdadero o Falso: Ya que el coeficiente de la interacción entre GPA y IQ es muy pequeño, no hay suficiente evidencia de que haya un término de interacción. Justifique su respuesta.

Falso: para verificar el coeficiente GPA/IQ hay que evaluar B4=0 para saber el valor-p asociado con t y F estadistico

## Problema 2

Para un modelo de regresión lineal simple, tenemos los coeficientes que minimizan al RSS:

$$\hat \beta_1 =\frac{\sum_{i=1}^{n}(x_i-\bar x)(y_i - \bar y)}{\sum_{i=1}^{n}(x_i-\bar x)^2}$$

$$\hat \beta_0 =\bar y - \hat \beta_1 \bar x$$

Muestre que dicha recta *siempre* pasa por el punto $(\bar x, \bar y)$.

y=B0+B1x

y=y-B1x+B1x

y=y 
 
por lo cual podemos concluir que siempre pasa por el punto (x,y)

# Problema Aplicado

Exploraremos los datos que podemos encontrar en `scikit-learn`. Empezamos cargando los paquetes necesarios (realizaremos ésto solamente en esta tarea; de aquí en adelante depende de usted de cargar los paquetes necesarios, así como documentar los utilizados):
"""

import numpy as np
import pandas as pd

import matplotlib
import matplotlib.pyplot as plt

import seaborn as sns

import patsy
from patsy import dmatrix

import sklearn
from sklearn.datasets import load_boston
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

print("Todos los paquetes han sido importados:")
print("Numpy version: {}".format(np.__version__))
print("Pandas version: {}".format(pd.__version__))
print("Matplotlib version: {}".format(matplotlib.__version__))
print("Seaborn version: {}".format(sns.__version__))
print("patsy version: {}".format(patsy.__version__))
print("Scikit-learn version: {}".format(sklearn.__version__))

"""## Modificando los parámetros de seaborn

Ésta parte es opcional, depende de su gusto para presentar gráficos. Para ver qué opciones tienen, [vean la documentación en seaborn](https://seaborn.pydata.org/tutorial/aesthetics.html).
"""

sns.set_style("whitegrid")
sns.set_context("talk")
sns.set(rc={"figure.figsize": (20, 20)})

"""## Un poco de EDA

`scikit-learn` tiene algunos datos que podemos acceder fácilmente. En éste caso, veremos los datos del precio de casas de Boston, pero si desea explorar algún otro, véa qué otros datos tiene disponible [`sklearn.datasets`](https://scikit-learn.org/stable/datasets/index.html#toy-datasets).
"""

boston = load_boston()

# Para ver qué traen los datos, vemos los keys:
print(boston.keys())

"""Por lo tanto, podemos acceder a los datos o predictores (`X`) mediante `boston.data` y a la variable de respuesta (`Y`) mediante `boston.target`. Asimismo, si deseamos ver la descripción de los datos, la cantidad de datos, etc., lo accedemos mediante `boston.DESCR` o bien `boston["DESCR"]`:"""

print(boston["DESCR"])

"""Vemos que queremos predecir el valor mediano de una casa en Boston. Convertimos a los datos en un DataFrame, aunque no es necesario. En efecto, podemos hacer:

```python
X = boston.data
Y = boston.target
```
lo cual bastaría. Sin embargo, procedemos de la forma más presentable, formando el DataFrame que usaremos:
"""

bos = pd.DataFrame(boston.data, columns=boston.feature_names)
bos["MEDV"] = boston.target

bos.head()

"""### Matriz de Correlación

La forma más sencilla de conseguir a la matriz de correlación es mediante [`.corr()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html):
"""

print(bos.corr())

"""No se mira muy bonito, así que otra forma de visualizar la correlación entre las variables es mediante un [`heatmap`](https://seaborn.pydata.org/generated/seaborn.heatmap.html):"""

cols = list(bos)
sns.set(font_scale=.75)

fig, ax = plt.subplots(figsize=(15,15))
sns.heatmap(bos.corr(), ax=ax, cbar=True, annot=True, fmt=".2f", square=True, yticklabels=cols, xticklabels=cols)
plt.show()

"""## Separando los datos en train y test

Proseguimos separando los datos en $\mathcal{T}_{\text{Tr}}$ y en $\mathcal{T}_{\text{Te}}$. Ésta vez tendremos que 

$$ |\mathcal{T}_{\text{Tr}}|/ |\mathcal{T}|=0.75 \qquad \text{ y }  \qquad |\mathcal{T}_{\text{Te}}|/| \mathcal{T}|=0.25 $$

Aunque no es una regla escrita en piedra. Además, tendremos `random_state=42` para que así se puedan reproducir los resultados de manera consistente. Usaremos, entonces a [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) de `scikit-learn`, el cual nos regresará 4 conjuntos de datos: a `X` separado en el conjunto de entrenamiento y prueba, y a `Y` separado en el conjunto de entrenamiento y de prueba, respectivamente:
"""

X = bos.drop("MEDV", axis=1)
Y = bos["MEDV"]

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)

print(X_train.shape)
print(Y_train.shape)

print(X_test.shape)
print(Y_test.shape)

"""#### Pregunta 1:

¿Existse evidencia de que alguno de sus datos tenga alto apalancamiento?

En el eje x tienen una diferencia de 252 por lo cual seria mejor un Leverage Statistic para conocer el apalancamiento.

Graficando se puede ver más fácil cual es el outlier.

## Regresión Lineal

Proseguimos utilizando ahora a [`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) de `scikit-learn`. Primero lo llamamos, luego lo entrenamos con los datos `X_train` usando `.fit()` y finalmente realizamos predicciones tanto en nuestros datos de entrenamiento como en los datos de prueba `X_test` y calculamos su error cuadrático medio:
"""

lm = LinearRegression()

lm.fit(X_train, Y_train)

# Realizamos predicciones:

pred_train = lm.predict(X_train)
pred_test = lm.predict(X_test)

# Definimos a 

mse_train = mean_squared_error(Y_train, pred_train)
mse_test = mean_squared_error(Y_test, pred_test)

print("Error cuadrático medio de entrenamiento: ", mse_train)
print("Error cuadrático medio de prueba: ", mse_test)

"""Si queremos acceder a los coeficientes del modelo, utilizamos a `.intercept_` para $\hat \beta_0$ y a `.coef_` para todos los otros $\hat \beta_j$:"""

print("beta_0={}".format(lm.intercept_))

print("Numero de predictores (sin intercepto):", len(lm.coef_))

print("beta_j: ",lm.coef_)

"""Podemos agruparlos en un solo dataframe para presentarlos de una mejor manera:"""

coeff = pd.DataFrame(list(zip(X.columns, lm.coef_)), columns=["Feature", "CoeficienteEstimado"])

inter = [{"Feature": "INTERCEPT", "CoeficienteEstimado": lm.intercept_}]

coeff = pd.concat([pd.DataFrame(inter), coeff], ignore_index=True)

print(coeff)

"""### Ejercicio 2: 

Obtenga los parametros obtenidos arriba usando NumPy, patsy, etc., como un `array`. Compararemos sus parámetros con `coeff` arriba y no debe de tirar error el programa. Defina a una función que luego llamará mediante el bloque

```python
beta = # Su función aquí
```
"""

def intercept (x_val,y_val):
  x=np.array(x_val)
  y=np.array(y_val)
  m=(((np.mean(x)*np.mean(y))- np.mean(x*y))/((np.mean(x)*np.mean(x))- np.mean(x*x)))
  m=round(m,2)
  b=(np.mean(y)-np.mean(x)*m)
  b=round(b,2)
  
  return m,b

intercept(X_train,Y_train)

beta = # Su función aquí

assert np.linalg.norm(coeff["EstimatedCoefficient"]-beta, ord=2) < 10**(-5), "¡Oh no, sus coeficientes son muy distintos! Revise su algoritmo."

"""## Regresion polinomial de grado 2

Puede que la regresión lineal no sea suficiente. Para ésto, podemos utilizar a [`PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) y a [`make_pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html). Primero convertimos a nuestras variables al grado que queremos y luego realizamos una regresión lineal:
"""

poly_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())

"""Proseguimos de la misma manera que antes: ajustamos al modelo utilizando a los datos de entrenamiento y luego realizamos predicciones"""

p = poly_model.fit(X_train, Y_train)

poly_pred_train = poly_model.predict(X_train)
poly_pred_test = poly_model.predict(X_test)

poly_mse_train = mean_squared_error(Y_train, poly_pred_train)
poly_mse_test = mean_squared_error(Y_test, poly_pred_test)

print("Error cuadrático medio de entrenamiento: ", poly_mse_train)
print("Error cuadrático medio de prueba: ", poly_mse_test)

"""### Ejercicio 3:

Grafique MSE_train y MSE_test para distintos grados de polinomio $d$, con $0\leq d \leq 5$. Concluya.

*Ayuda: Defina una función que haga de manera automática nuestro procedimiento anterior. Luego grafique a los MSE de entrenamiento y prueba y vea cuál grado de polinomio minimiza el de prueba. Puede usar, de envés de MSE, al logaritmo de éste mediante `np.log` para poder visualizar fácilmente a alos errores de prueba.*
"""

def graficaErrores(d, xSet, ySet):
  poly_model = make_pipeline(PolynomialFeatures(degree=d), LinearRegression())
  p = poly_model.fit(xSet, ySet)
  pred = p.predict(xSet)
  resid = ySet - pred

  sns.set(rc={'figure.figsize':(11.7,8.27)})
  sns.residplot(pred, resid, lowess=True, color="g")

graficaErrores(1, X_train, Y_train)

train = []
test = []
d = [0,1,2,3,4,5]
for i in range(0,6):
  
  poly_model = make_pipeline(PolynomialFeatures(degree= i), LinearRegression())
  p = poly_model.fit(X_train, Y_train)

  poly_pred_train = poly_model.predict(X_train)
  poly_pred_test = poly_model.predict(X_test)

  poly_mse_train = mean_squared_error(Y_train, poly_pred_train)
  poly_mse_test = mean_squared_error(Y_test, poly_pred_test)
  
  train.append(poly_mse_train)
  test.append(poly_mse_test)

#Train
plt.plot(d, train);
plt.title("Train")
plt.xlabel("grado")
plt.ylabel("error")

#Test
plt.plot(d, test);
plt.title("Test")
plt.xlabel("grado")
plt.ylabel("error")